[
    {
        "title": "Unable to install blar graph with the specified version",
        "id": 2847690670,
        "state": "open",
        "first": "Failing at the installation level. Which is the right version of blar graph? \nERROR: Could not find a version that satisfies the requirement blar-graph==1.1.6 (from versions: none)\nERROR: No matching distribution found for blar-graph==1.1.6\nrequirements.txt file in the main branch is as below:\nfastapi[all]==0.115.6\ninstructor==1.5.2\njiter==0.5.0\nlitellm==1.59.9\njoblib==1.4.2\njson_repair==0.35.0\nlangsmith==0.3.3\njson5==0.9.28\nkombu==5.4.2\nuvicorn==0.32.1\nsqlalchemy==2.0.36\nalembic==1.14.0\ngunicorn==23.0.0\npython-dotenv==1.0.1\npostgres==4.0\npsycopg2-binary==2.9.10\nneo4j==5.27.0\ntree-sitter==0.20.4\ntree-sitter-languages==1.10.2\ntqdm==4.67.1\ngrep-ast==0.4.1\npygments==2.18.0\nnetworkx==3.4.2\nblar-graph==1.1.6\nopenai==1.60.2\nuuid6==2024.7.10\naiohttp==3.11.9\nlangchain==0.3.16\nlangchain-anthropic==0.3.4\nlangchain-deepseek-official==0.1.0\nlangchain-community==0.3.16\nlangchain-core==0.3.32\nlangchain-openai==0.3.2\nlanggraph-checkpoint==2.0.10\nlanggraph-sdk==0.1.51\nlangchain-postgres==0.0.12\nlanggraph==0.2.58\nfirebase-admin==6.6.0\nportkey-ai==1.9.7\ngitPython==3.1.43\nPyGithub==2.5.0\ngoogle-cloud-secret-manager==2.21.1\npre-commit==4.0.1\nisort==5.13.2\nblack==24.10.0\nruff==0.8.1\npylint==3.3.2\nbandit==1.8.0\naiofiles==24.1.0\nscikit-learn==1.5.2\nrequests==2.32.3\nresend==2.4.0\ntransformers==4.46.3\ntorch==2.5.1\nsentence-transformers==3.3.1\ncrewai==0.95.0\nnltk==3.9.1\ncelery==5.4.0\nredis==5.2.0\nflower==2.0.1\nchardet==5.2.0\nsentry-sdk[fastapi]==2.20.0\nposthog==3.7.4\nnewrelic==9.0.0\ntiktoken==0.7.0\nagentops==0.3.26\npydantic[email]==2.10.3\nfirecrawl-py==1.11.1",
        "messages": "Failing at the installation level. Which is the right version of blar graph? \nERROR: Could not find a version that satisfies the requirement blar-graph==1.1.6 (from versions: none)\nERROR: No matching distribution found for blar-graph==1.1.6\nrequirements.txt file in the main branch is as below:\nfastapi[all]==0.115.6\ninstructor==1.5.2\njiter==0.5.0\nlitellm==1.59.9\njoblib==1.4.2\njson_repair==0.35.0\nlangsmith==0.3.3\njson5==0.9.28\nkombu==5.4.2\nuvicorn==0.32.1\nsqlalchemy==2.0.36\nalembic==1.14.0\ngunicorn==23.0.0\npython-dotenv==1.0.1\npostgres==4.0\npsycopg2-binary==2.9.10\nneo4j==5.27.0\ntree-sitter==0.20.4\ntree-sitter-languages==1.10.2\ntqdm==4.67.1\ngrep-ast==0.4.1\npygments==2.18.0\nnetworkx==3.4.2\nblar-graph==1.1.6\nopenai==1.60.2\nuuid6==2024.7.10\naiohttp==3.11.9\nlangchain==0.3.16\nlangchain-anthropic==0.3.4\nlangchain-deepseek-official==0.1.0\nlangchain-community==0.3.16\nlangchain-core==0.3.32\nlangchain-openai==0.3.2\nlanggraph-checkpoint==2.0.10\nlanggraph-sdk==0.1.51\nlangchain-postgres==0.0.12\nlanggraph==0.2.58\nfirebase-admin==6.6.0\nportkey-ai==1.9.7\ngitPython==3.1.43\nPyGithub==2.5.0\ngoogle-cloud-secret-manager==2.21.1\npre-commit==4.0.1\nisort==5.13.2\nblack==24.10.0\nruff==0.8.1\npylint==3.3.2\nbandit==1.8.0\naiofiles==24.1.0\nscikit-learn==1.5.2\nrequests==2.32.3\nresend==2.4.0\ntransformers==4.46.3\ntorch==2.5.1\nsentence-transformers==3.3.1\ncrewai==0.95.0\nnltk==3.9.1\ncelery==5.4.0\nredis==5.2.0\nflower==2.0.1\nchardet==5.2.0\nsentry-sdk[fastapi]==2.20.0\nposthog==3.7.4\nnewrelic==9.0.0\ntiktoken==0.7.0\nagentops==0.3.26\npydantic[email]==2.10.3\nfirecrawl-py==1.11.1\n---\nHi @jai2033shankar thanks for trying out potpie! Can you please verify that your version of python is 3.10 as that is a requirement for blar.\n---\n> Hi [@jai2033shankar](https://github.com/jai2033shankar) thanks for trying out potpie! Can you please verify that your version of python is 3.10 as that is a requirement for blar.\n(venv) (base) jai@Jais-MacBook-Air potpie % python --version\nPython 3.12.7\n---\nPlease try with Python 3.10, I just tried `pip install --no-cache-dir blar-graph==1.1.6` and pip was able to resolve the version on Python 3.10\n---\nSure"
    },
    {
        "title": "Inconsistent Status Codes for Resource Creation (201 vs. 200)",
        "id": 2846653526,
        "state": "open",
        "first": "I noticed that in several places within the backend, we are returning 200 OK for resource creation instead of 201 Created. According to [MDN documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/201), 201 is the appropriate status code when a new resource is successfully created.\n![Image](https://github.com/user-attachments/assets/c3d4dbdd-a87f-4048-a077-42b1f6fadee2)\nSteps to Reproduce:\n    Make a request to create a resource (e.g., POST /api/v1/conversations/).\n    Observe the response status code (should be 201 but sometimes returns 200).\nAffected Endpoints:\n    POST `/api/v1/signup` \n    POST `/api/v1/parse`\n    POST `/api/v1/conversations/`,  \n    POST `/api/v1/conversations/{conversation_id}/message/`,  \nmaybe more but this is the scope of my Issue. \nExpected Behavior:\n    When a resource is created, the API should return 201 Created instead of 200 OK.\n    Consistent usage of status codes across the project.\nProposed Fix:\n    Update all affected endpoints to return 201 Created when a resource is successfully created.\n    Review API responses for consistency.",
        "messages": "I noticed that in several places within the backend, we are returning 200 OK for resource creation instead of 201 Created. According to [MDN documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/201), 201 is the appropriate status code when a new resource is successfully created.\n![Image](https://github.com/user-attachments/assets/c3d4dbdd-a87f-4048-a077-42b1f6fadee2)\nSteps to Reproduce:\n    Make a request to create a resource (e.g., POST /api/v1/conversations/).\n    Observe the response status code (should be 201 but sometimes returns 200).\nAffected Endpoints:\n    POST `/api/v1/signup` \n    POST `/api/v1/parse`\n    POST `/api/v1/conversations/`,  \n    POST `/api/v1/conversations/{conversation_id}/message/`,  \nmaybe more but this is the scope of my Issue. \nExpected Behavior:\n    When a resource is created, the API should return 201 Created instead of 200 OK.\n    Consistent usage of status codes across the project.\nProposed Fix:\n    Update all affected endpoints to return 201 Created when a resource is successfully created.\n    Review API responses for consistency.\n---\nHi\n---\n@RudolfPleml  are you a bot? \nif not are you new to github ??"
    },
    {
        "title": "Please Stop Spamming Developers via Email",
        "id": 2825136435,
        "state": "open",
        "first": "Hello,\nI and other developers have been receiving unsolicited emails from your team with subjects like \"_Seeking Developers to Integrate DeepSeek R1 into PotpieAI_\". It seems that you are using GitHub emails for mass outreach, which is not only unwanted but also considered spam.\nIf this continues, I (and likely others) will have no choice but to file abuse reports against your hosting provider for mass email spam and report your GitHub account for violating platform policies.\n**I strongly urge you to reconsider this approach and respect developers' inboxes.**\n**_Thank you for your understanding._**\n![Image](https://github.com/user-attachments/assets/fcdc6a0b-5f4b-4c36-8bb3-a9d40fcad823)\n![Image](https://github.com/user-attachments/assets/082c610c-b4f6-40f2-b073-b7749653659b)\nYou can get more details here:\n[Seeking Developers to Integrate DeepSeek R1 into PotpieAI.eml.txt](https://github.com/user-attachments/files/18628382/Seeking.Developers.to.Integrate.DeepSeek.R1.into.PotpieAI.eml.txt)",
        "messages": "Hello,\nI and other developers have been receiving unsolicited emails from your team with subjects like \"_Seeking Developers to Integrate DeepSeek R1 into PotpieAI_\". It seems that you are using GitHub emails for mass outreach, which is not only unwanted but also considered spam.\nIf this continues, I (and likely others) will have no choice but to file abuse reports against your hosting provider for mass email spam and report your GitHub account for violating platform policies.\n**I strongly urge you to reconsider this approach and respect developers' inboxes.**\n**_Thank you for your understanding._**\n![Image](https://github.com/user-attachments/assets/fcdc6a0b-5f4b-4c36-8bb3-a9d40fcad823)\n![Image](https://github.com/user-attachments/assets/082c610c-b4f6-40f2-b073-b7749653659b)\nYou can get more details here:\n[Seeking Developers to Integrate DeepSeek R1 into PotpieAI.eml.txt](https://github.com/user-attachments/files/18628382/Seeking.Developers.to.Integrate.DeepSeek.R1.into.PotpieAI.eml.txt)\n---\nHey @GiaNTizmO \nReally sorry about that and I appreciate you being candid here! Here's what I am going to do -\n- Usually there is an unsubscribe option - will check why it didn't show up for you.\n- Make sure you don't receive any further emails from us. In case, it ever happens again please consider it a mistake and let me know either by emailing me (aditi@potpie.ai) or DMing me on discord.\n- Lastly, it wasn't an attempt to spam you but we genuinely wanted to connect with developers like you to help us - that is the only way open-source companies like ours can thrive. So I would love to talk to you and demonstrate our product if you are up for it. I promise it will be only 15 mins and well utilised."
    },
    {
        "title": "Fails to parse local repository",
        "id": 2817998130,
        "state": "open",
        "first": "Hi!\nI tried to run the project locally to support the development of a Ollama integration, but I wasn't able to get a local repo parsed with the current functionality.\nI followed the guide and the server is running, but every time when I'm trying to parse a local repository:\n```\ncurl -X POST 'http://localhost:8001/api/v1/parse' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"repo_path\": \"[MY_REPO_PATH]\",\n    \"branch_name\": \"main\"\n  }'\n```\nIt returns\n```\ncurl: (52) Empty reply from server\n```\nand the server log is\n```\nINFO:root:Development mode enabled. Using Mock Authentication.\nINFO:root:Development mode enabled. Using environment variable for API key.\nINFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\nINFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n[2025-01-29 12:40:17 +0100] [94464] [ERROR] Worker (pid:95339) was sent SIGABRT!\n/Users/[MY_USERNAME]/.pyenv/versions/3.10.16/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n  warnings.warn('resource_tracker: There appear to be %d '\n[2025-01-29 12:40:17 +0100] [95491] [INFO] Booting worker with pid: 95491\nINFO:app.celery.celery_app:Connecting to Redis at: redis://127.0.0.1:6379/0\nINFO:app.celery.celery_app:Successfully connected to Redis\n[nltk_data] Downloading package punkt_tab to /Users/[MY_USERNAME]/Document\n[nltk_data]     s/Workspace/Python/potpie/venv/lib/python3.10/site-\n[nltk_data]     packages/llama_index/core/_static/nltk_cache...\n[nltk_data]   Package punkt_tab is already up-to-date!\nINFO:app.celery.tasks.parsing_tasks:Parsing tasks module loaded\nINFO:root:Development mode enabled. Skipping Firebase setup.\nDummy user already exists\nINFO:root:Dummy user created\n[2025-01-29 12:40:21 +0100] [95491] [INFO] Started server process [95491]\n[2025-01-29 12:40:21 +0100] [95491] [INFO] Waiting for application startup.\nINFO:root:System prompts initialized successfully\n[2025-01-29 12:40:22 +0100] [95491] [INFO] Application startup complete.\n```\nDo you have any idea what is configured wrong on my side?\nThanks!",
        "messages": "Hi!\nI tried to run the project locally to support the development of a Ollama integration, but I wasn't able to get a local repo parsed with the current functionality.\nI followed the guide and the server is running, but every time when I'm trying to parse a local repository:\n```\ncurl -X POST 'http://localhost:8001/api/v1/parse' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"repo_path\": \"[MY_REPO_PATH]\",\n    \"branch_name\": \"main\"\n  }'\n```\nIt returns\n```\ncurl: (52) Empty reply from server\n```\nand the server log is\n```\nINFO:root:Development mode enabled. Using Mock Authentication.\nINFO:root:Development mode enabled. Using environment variable for API key.\nINFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\nINFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n[2025-01-29 12:40:17 +0100] [94464] [ERROR] Worker (pid:95339) was sent SIGABRT!\n/Users/[MY_USERNAME]/.pyenv/versions/3.10.16/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n  warnings.warn('resource_tracker: There appear to be %d '\n[2025-01-29 12:40:17 +0100] [95491] [INFO] Booting worker with pid: 95491\nINFO:app.celery.celery_app:Connecting to Redis at: redis://127.0.0.1:6379/0\nINFO:app.celery.celery_app:Successfully connected to Redis\n[nltk_data] Downloading package punkt_tab to /Users/[MY_USERNAME]/Document\n[nltk_data]     s/Workspace/Python/potpie/venv/lib/python3.10/site-\n[nltk_data]     packages/llama_index/core/_static/nltk_cache...\n[nltk_data]   Package punkt_tab is already up-to-date!\nINFO:app.celery.tasks.parsing_tasks:Parsing tasks module loaded\nINFO:root:Development mode enabled. Skipping Firebase setup.\nDummy user already exists\nINFO:root:Dummy user created\n[2025-01-29 12:40:21 +0100] [95491] [INFO] Started server process [95491]\n[2025-01-29 12:40:21 +0100] [95491] [INFO] Waiting for application startup.\nINFO:root:System prompts initialized successfully\n[2025-01-29 12:40:22 +0100] [95491] [INFO] Application startup complete.\n```\nDo you have any idea what is configured wrong on my side?\nThanks!\n---\ni have the same issue.\n---\n@ripcurlx @wikando-mz  I was also facing same issue. If you are using mac machine with M1/M2/M3 chip, you have to replace below code in inference_service.py:\n`self.embedding_model = SentenceTransformer(\n            \"all-MiniLM-L6-v2\")\n`\nwith \n```\nself.embedding_model = SentenceTransformer(\n            \"all-MiniLM-L6-v2\", device='cpu')\n```\nFor me this worked\n---\nHi @ripcurlx did you try the solution by @chikka  above? I was not able to reproduce your issue. \nCan you provide more details about your machine?"
    },
    {
        "title": "Create a CLI for using potpie locally ",
        "id": 2777259549,
        "state": "open",
        "first": "# Create Development CLI for Local PotPie Usage\n## Objective\nCreate a command-line interface for local development interactions with PotPie.\n## Commands\n### 0. init \n```bash \npotpie start\n``` \nand \n```bash\npotpie stop\n```\ncommands to turn on and off the server. \n### 1. parse\n```bash\npotpie parse <repo-path> [--branch <branch-name>]\n```\n- Submit repository for parsing\n- Poll status until complete\n- Display progress/status\n- Block until ready\n### 2. chat\n```bash\npotpie chat <project-id> --agent <agent-name> [--branch <branch-name>]\n```\n- Validate project readiness\n- Initialize conversation with specified agent\n- Interactive console for messages\n- Display responses\n## Requirements\n- Input validation for repo paths and branches\n- Status feedback during parsing\n- Error handling for invalid inputs\n- Clean console output formatting\n- Session management for chat\n## Success Criteria\n- [ ] Successfully parses repositories\n- [ ] Shows parse status clearly\n- [ ] Validates project status\n- [ ] Handles errors gracefully",
        "messages": "# Create Development CLI for Local PotPie Usage\n## Objective\nCreate a command-line interface for local development interactions with PotPie.\n## Commands\n### 0. init \n```bash \npotpie start\n``` \nand \n```bash\npotpie stop\n```\ncommands to turn on and off the server. \n### 1. parse\n```bash\npotpie parse <repo-path> [--branch <branch-name>]\n```\n- Submit repository for parsing\n- Poll status until complete\n- Display progress/status\n- Block until ready\n### 2. chat\n```bash\npotpie chat <project-id> --agent <agent-name> [--branch <branch-name>]\n```\n- Validate project readiness\n- Initialize conversation with specified agent\n- Interactive console for messages\n- Display responses\n## Requirements\n- Input validation for repo paths and branches\n- Status feedback during parsing\n- Error handling for invalid inputs\n- Clean console output formatting\n- Session management for chat\n## Success Criteria\n- [ ] Successfully parses repositories\n- [ ] Shows parse status clearly\n- [ ] Validates project status\n- [ ] Handles errors gracefully\n---\n/bounty 10\n---\n/attempt #224\r\n<div id=\"algora-attempt\" />\n<details>\n  <summary>Options</summary>\n  <ul>\n    <li>\n      <a href=\"https://console.algora.io/api/bounties/cm5p474bd000hks03ji75nkca/cancel-attempt\">\n        Cancel my attempt\n      </a>\n    </li>\n  </ul>\n</details>\n---\n/attempt #224\nHey I am solving this issue but I will project structure refactoring, @dhirenmathur  will go to need your help to improve \n<div id=\"algora-attempt\" />\n<details>\n  <summary>Options</summary>\n  <ul>\n    <li>\n      <a href=\"https://console.algora.io/api/bounties/cm5p474bd000hks03ji75nkca/cancel-attempt\">\n        Cancel my attempt\n      </a>\n    </li>\n  </ul>\n</details>\n---\n@DeepeshKalura go for it! Please share a plan before implementing! Thank you for your contribution!\n---\n@dhirenmathur Yeah, I was going to tell you that. \nSo, Currently, I see that we manage the server startup with ` ./start.sh`.\nLet's start the I will use click to create CLI as it pre-install the package with fastAPI. And super easy to use. ( If you want i don't mind using a more traditional `argparse` to build CLI. \nSo, If I see this PR and just focus that thing in mind then.  I will add the click code on the server code.  For example, would be. \nin app > main.py.\n```python\ndef start_server():\n    uvicorn.run(app, host=\"0.0.0.0\", port=8034,)\ndef stop_server():\n    pass\n@click.group()\ndef cli():\n    pass\n@cli.command()\ndef start():\n    start_server()\n@cli.command()\ndef stop():\n    stop_server()\nif __name__ == \"__main__\":\n    cli()\n``` \nJust add these lines on the end. Yes all of these will work, Similarly then I will create singletion instance of cli and pass where I need from the serve code as the reference and make a wrapper similar code with cli. I think it work for small projects. ( Yeah I know it destroys the separate of concern  case here ) \nbut it will work. \nKey points will 1. Single Instance of CLI and use the server ( fastapi )  wrapper around the CLI if needed. \nI think you will avoid such code. I will also avoid it.\nSo, I was thinking to create a separate CLI logic that will be the same but it will separate instance. \nMore like one file or folder. \nMaybe I am in right directions of  thinking.\n---\nWould like to give it a try as I have worked on CLI's before...\n---\n/attempt https://github.com/potpie-ai/potpie/issues/224\n---\nHey @Savio629 I think @DeepeshKalura is already working on this issue. \nYou are welcome to give it a try parallelly if you want, but the bounty will be awarded to the solution that will best suit the requirements in the end.\n---\nHey @DeepeshKalura . Using click is good. Please DM me on discord if you're still working on this, I would like to understand your proposal better.\n---\n@dhirenmathur  yes I am working on this can, Ok joining discord\n---\n@dhirenmathur I read the requirement \"Poll status until complete\" I don't think it good idea ( because we cannot tell how much time it will take as API is not telling it. I will have a better idea. I just dm you.\n---\n/attempt #224\n<div id=\"algora-attempt\" />\n<details>\n  <summary>Options</summary>\n  <ul>\n    <li>\n      <a href=\"https://console.algora.io/api/bounties/cm5p474bd000hks03ji75nkca/cancel-attempt\">\n        Cancel my attempt\n      </a>\n    </li>\n  </ul>\n</details>\n---\n@riturajFi  bro you are super late for this. I think Fulfil the requirements currently writing tests. So, I think you waste time on this issue. Just a warning bro!"
    },
    {
        "title": "Implement inference caching while knowledge graph generation ",
        "id": 2777242939,
        "state": "open",
        "first": "# Implement Hash-Based Caching for Knowledge Graph Nodes\r\n## Objective \r\nOptimize knowledge graph generation across branches by implementing hash-based caching for node inference and embeddings.\r\n## Current Behavior\r\n- Complete knowledge graph regeneration for each new branch\r\n- Redundant inference generation for unchanged nodes\r\n## Proposed Solution\r\n- Calculate and store hash for each node in graph\r\n- Compare node hashes between branches\r\n- Reuse inference and embeddings for matching hashes\r\n- Generate new inference only for modified nodes\r\n## Implementation\r\n1. Add hash generation for nodes\r\n2. Store hashes in graph structure\r\n3. Implement hash comparison system\r\n4. Add cache lookup before inference\r\n5. Copy matching node data from cache\r\n## Success Criteria\r\n- [ ] Hash generation working correctly\r\n- [ ] Cache hit/miss working as expected\r\n- [ ] Faster graph generation for similar branches\r\n- [ ] No loss in inference quality",
        "messages": "# Implement Hash-Based Caching for Knowledge Graph Nodes\r\n## Objective \r\nOptimize knowledge graph generation across branches by implementing hash-based caching for node inference and embeddings.\r\n## Current Behavior\r\n- Complete knowledge graph regeneration for each new branch\r\n- Redundant inference generation for unchanged nodes\r\n## Proposed Solution\r\n- Calculate and store hash for each node in graph\r\n- Compare node hashes between branches\r\n- Reuse inference and embeddings for matching hashes\r\n- Generate new inference only for modified nodes\r\n## Implementation\r\n1. Add hash generation for nodes\r\n2. Store hashes in graph structure\r\n3. Implement hash comparison system\r\n4. Add cache lookup before inference\r\n5. Copy matching node data from cache\r\n## Success Criteria\r\n- [ ] Hash generation working correctly\r\n- [ ] Cache hit/miss working as expected\r\n- [ ] Faster graph generation for similar branches\r\n- [ ] No loss in inference quality\n---\n/bounty 10\n---\n/attempt #223\n<div id=\"algora-attempt\" />\n| [Algora profile](https://console.algora.io/@/onyedikachi-david) | Completed bounties | Tech | Active attempts | Options |\n| --- | --- | --- | --- | --- |\n| @onyedikachi-david | 14 bounties from 7 projects | <div align=\"center\">TypeScript, Python, <br />JavaScript & more</div> | <div align=\"center\"></div> | [Cancel attempt](https://console.algora.io/api/bounties/cm5p3xdcn0006i803268k2yfp/cancel-attempt) |"
    },
    {
        "title": "Support multiple LLMs through Litellm",
        "id": 2777233161,
        "state": "open",
        "first": "# Replace LangChain Chat Clients with LiteLLM\r\n## Objective\r\nReplace all LangChain chat client implementations with LiteLLM while maintaining existing functionality.\r\nAPIs to manage user's LLM choice and keys and ensure that right LLM is selected during processing and agent execution.\r\n## Requirements\r\n- Keep existing provider service pattern intact\r\n- Support all current LLMs through LiteLLM\r\n- Maintain inference and agent interaction functionality\r\n- Remove CrewAI specialized handling (This was added because crewai was not able to support anthropic through the langchain client due to some conflict witht their internal litellm) \r\n- Preserve streaming functionality\r\n## Implementation\r\n1. Replace LangChain imports with LiteLLM\r\n2. Update provider services\r\n3. Remove CrewAI-client specific code\r\n4. Update configurations and environment variables\r\n## Testing\r\n- Verify provider service functionality\r\n- Test all LLM integrations\r\n- Validate inference and agent operations\r\n- Check streaming implementations\r\n- Run existing test suite\r\n## Success Criteria\r\n- [ ] All LangChain chat clients replaced\r\n- [ ] Potpie supports any model that is supported by Litellm \r\n- [ ] User is able to set preference and keys for their LLM of choice\r\n- [ ] No breaks in existing functionality\r\n- [ ] Streaming working as expected",
        "messages": "# Replace LangChain Chat Clients with LiteLLM\r\n## Objective\r\nReplace all LangChain chat client implementations with LiteLLM while maintaining existing functionality.\r\nAPIs to manage user's LLM choice and keys and ensure that right LLM is selected during processing and agent execution.\r\n## Requirements\r\n- Keep existing provider service pattern intact\r\n- Support all current LLMs through LiteLLM\r\n- Maintain inference and agent interaction functionality\r\n- Remove CrewAI specialized handling (This was added because crewai was not able to support anthropic through the langchain client due to some conflict witht their internal litellm) \r\n- Preserve streaming functionality\r\n## Implementation\r\n1. Replace LangChain imports with LiteLLM\r\n2. Update provider services\r\n3. Remove CrewAI-client specific code\r\n4. Update configurations and environment variables\r\n## Testing\r\n- Verify provider service functionality\r\n- Test all LLM integrations\r\n- Validate inference and agent operations\r\n- Check streaming implementations\r\n- Run existing test suite\r\n## Success Criteria\r\n- [ ] All LangChain chat clients replaced\r\n- [ ] Potpie supports any model that is supported by Litellm \r\n- [ ] User is able to set preference and keys for their LLM of choice\r\n- [ ] No breaks in existing functionality\r\n- [ ] Streaming working as expected\n---\nNeed to think about how to select the correct provider, model and key\n---\n/bounty 10\n---\n/bounty 50\n---\n/attempt #222\n<div id=\"algora-attempt\" />\n<details>\n  <summary>Options</summary>\n  <ul>\n    <li>\n      <a href=\"https://console.algora.io/api/bounties/cm5p3sjis0004ks037atz80ab/cancel-attempt\">\n        Cancel my attempt\n      </a>\n    </li>\n  </ul>\n</details>\n---\n/attempt #222\n<div id=\"algora-attempt\" />\n<details>\n  <summary>Options</summary>\n  <ul>\n    <li>\n      <a href=\"https://console.algora.io/api/bounties/cm5p3sjis0004ks037atz80ab/cancel-attempt\">\n        Cancel my attempt\n      </a>\n    </li>\n  </ul>\n</details>\n---\n@dhirenmathur does we have to support all llm with litellm or the llm which are present in current application for those just we have to change from langchain to lite\n---\nand also does i have to completely remove langchain in all aspects like - prompttemplates , tool calls or just the chat\n---\nhey @PRANJALRANA11  we want to incorporate litellm across the app so that we can support all LLMs. We use instances of langchain client and the crewai client, this makes the provider_service and agent code really messy, ideally we want to replace both with a single litellm instance. \nYes if we are not going to use the langchain client then it does not make sense to keep the prompt template etc. \nFor tools, I think we can continue with langchain tools, what do you think?\n---\nHey @dfordp , Thanks for attempting this! In the interest of time, I'm assigning this to @PRANJALRANA11 since there have been no follow up messages in ~10 days. We will have other open issues for you to contribute on when you're ready!\n---\n@dhirenmathur sorry I wasn't able to do it,  I was 50% through to doing it but got busy with work."
    },
    {
        "title": "Incremental Knowledge Graph updates",
        "id": 2777157141,
        "state": "open",
        "first": "# Implement Incremental Knowledge Graph Updates\r\n## Problem\r\nCurrently, the knowledge graph system performs a complete rebuild of both code mapping and inference generation on any update, regardless of the change magnitude. This approach is computationally expensive and time-consuming, impacting system performance and resource utilization.\r\n## Proposed Solution\r\nDevelop an incremental update system for the knowledge graph that processes only the changed components rather than rebuilding the entire graph.\r\n## Requirements\r\n### Core Functionality\r\n- Implement differential analysis to detect and isolate changes between versions\r\n- Create an incremental update mechanism that preserves existing graph structure\r\n- Develop a system to track and maintain relationship integrity during updates\r\n### Key Features\r\n1. **Change Detection**\r\n   - Identify modified, added, and deleted components\r\n   - Determine affected relationships and dependencies\r\n   - Map impact scope of changes\r\n2. **Relationship Management**\r\n   - Maintain accurate relationship tracking across updates\r\n   - Handle cascading relationship updates\r\n   - Preserve existing relationship metadata\r\n3. **Inference Handling**\r\n   - Generate inferences only for new/modified components\r\n   - Preserve existing valid inferences\r\n   - Update affected inference chains without full regeneration\r\n4. **Performance Optimization**\r\n   - Eliminate full graph reconstruction\r\n   - Minimize parsing operations to affected components only\r\n   - Optimize resource usage during updates\r\n## Technical Considerations\r\n- Must maintain data consistency throughout incremental updates\r\n- Need to implement versioning/tracking for incremental changes\r\n- Requires robust error handling for partial updates\r\n- Should include rollback capability for failed updates",
        "messages": "# Implement Incremental Knowledge Graph Updates\r\n## Problem\r\nCurrently, the knowledge graph system performs a complete rebuild of both code mapping and inference generation on any update, regardless of the change magnitude. This approach is computationally expensive and time-consuming, impacting system performance and resource utilization.\r\n## Proposed Solution\r\nDevelop an incremental update system for the knowledge graph that processes only the changed components rather than rebuilding the entire graph.\r\n## Requirements\r\n### Core Functionality\r\n- Implement differential analysis to detect and isolate changes between versions\r\n- Create an incremental update mechanism that preserves existing graph structure\r\n- Develop a system to track and maintain relationship integrity during updates\r\n### Key Features\r\n1. **Change Detection**\r\n   - Identify modified, added, and deleted components\r\n   - Determine affected relationships and dependencies\r\n   - Map impact scope of changes\r\n2. **Relationship Management**\r\n   - Maintain accurate relationship tracking across updates\r\n   - Handle cascading relationship updates\r\n   - Preserve existing relationship metadata\r\n3. **Inference Handling**\r\n   - Generate inferences only for new/modified components\r\n   - Preserve existing valid inferences\r\n   - Update affected inference chains without full regeneration\r\n4. **Performance Optimization**\r\n   - Eliminate full graph reconstruction\r\n   - Minimize parsing operations to affected components only\r\n   - Optimize resource usage during updates\r\n## Technical Considerations\r\n- Must maintain data consistency throughout incremental updates\r\n- Need to implement versioning/tracking for incremental changes\r\n- Requires robust error handling for partial updates\r\n- Should include rollback capability for failed updates\n---\n/bounty 20\n---\n/attempt #221\n<div id=\"algora-attempt\" />\n<details>\n  <summary>Options</summary>\n  <ul>\n    <li>\n      <a href=\"https://console.algora.io/api/bounties/cm5p3bnjw0002ks03n8d2kxeu/cancel-attempt\">\n        Cancel my attempt\n      </a>\n    </li>\n  </ul>\n</details>\n---\nHey @Harihara04sudhan do you have a plan on how to go about this?\n---\n/attempt #221\n<div id=\"algora-attempt\" />\n| [Algora profile](https://console.algora.io/@/onyedikachi-david) | Completed bounties | Tech | Active attempts | Options |\n| --- | --- | --- | --- | --- |\n| @onyedikachi-david | 14 bounties from 7 projects | <div align=\"center\">TypeScript, Python, <br />JavaScript & more</div> | <div align=\"center\"></div> | [Cancel attempt](https://console.algora.io/api/bounties/cm5p3bnjw0002ks03n8d2kxeu/cancel-attempt) |"
    },
    {
        "title": "Unable to add custom API key on key management",
        "id": 2774471759,
        "state": "closed",
        "first": "Hey @dhirenmathur, was checking out Potpie, and wanted to add my custom key to the Dashboard for trying out the platform. \r\nI'm unable to add my own key, getting a 404 when inspecting the API call. This was my first time signing up. \r\n![image](https://github.com/user-attachments/assets/a40b452b-60ff-4244-8980-07996de2106b)\r\nAlso, suggestion for you, move to [LiteLLM](https://www.litellm.ai/) to support more LLM providers.",
        "messages": "Hey @dhirenmathur, was checking out Potpie, and wanted to add my custom key to the Dashboard for trying out the platform. \r\nI'm unable to add my own key, getting a 404 when inspecting the API call. This was my first time signing up. \r\n![image](https://github.com/user-attachments/assets/a40b452b-60ff-4244-8980-07996de2106b)\r\nAlso, suggestion for you, move to [LiteLLM](https://www.litellm.ai/) to support more LLM providers.\n---\nThanks for reporting this @rachittshah , I will get this checked out. \nYes we are evaluating Litellm too! Thanks for the suggestion!\n---\n@rachittshah please try now! Let me know if you run into any issues\n---\n@rachittshah I think it should be resolved. I am closing this issue. Please comment here if it needs to be reopened. Thanks!"
    },
    {
        "title": "Test Algora",
        "id": 2770042568,
        "state": "closed",
        "first": "/bounty 1",
        "messages": "/bounty 1\n---\nSeems your test worked"
    },
    {
        "title": "Anthropic-specific prompts needed for classification and agent tasks",
        "id": 2737714481,
        "state": "open",
        "first": "## Issue Summary\r\nWhile PR #203 fixed basic Anthropic integration, the current prompts are not optimized for Anthropic models. We need to update classification prompts and agent task descriptions to improve performance with Anthropic models while work continues on dynamic prompt injection (#189).\r\n## Current Status\r\n- Anthropic integration is technically working after PR #203\r\n- Existing prompts designed for other models perform sub-optimally with Anthropic\r\n- Work in progress on dynamic prompt injection based on model name (#189)\r\n- Classification and agent task prompts need immediate updates\r\n## Action Items\r\n- [ ] Review and update classification prompts for Anthropic compatibility\r\n- [ ] Revise agent task descriptions to align with Anthropic's capabilities\r\n- [ ] Test updated prompts with Anthropic models\r\n- [ ] Document Anthropic-specific prompt patterns that work well\r\n## Related Issues/PRs\r\n- #189 Dynamic prompt injection based on model name\r\n- #203 Basic Anthropic integration fix\r\n## Additional Context\r\nThis is an interim solution while the more comprehensive dynamic prompt injection system is being developed. Once #189 is completed, these Anthropic-specific prompts can be integrated into the dynamic system.",
        "messages": "## Issue Summary\r\nWhile PR #203 fixed basic Anthropic integration, the current prompts are not optimized for Anthropic models. We need to update classification prompts and agent task descriptions to improve performance with Anthropic models while work continues on dynamic prompt injection (#189).\r\n## Current Status\r\n- Anthropic integration is technically working after PR #203\r\n- Existing prompts designed for other models perform sub-optimally with Anthropic\r\n- Work in progress on dynamic prompt injection based on model name (#189)\r\n- Classification and agent task prompts need immediate updates\r\n## Action Items\r\n- [ ] Review and update classification prompts for Anthropic compatibility\r\n- [ ] Revise agent task descriptions to align with Anthropic's capabilities\r\n- [ ] Test updated prompts with Anthropic models\r\n- [ ] Document Anthropic-specific prompt patterns that work well\r\n## Related Issues/PRs\r\n- #189 Dynamic prompt injection based on model name\r\n- #203 Basic Anthropic integration fix\r\n## Additional Context\r\nThis is an interim solution while the more comprehensive dynamic prompt injection system is being developed. Once #189 is completed, these Anthropic-specific prompts can be integrated into the dynamic system.\n---\n@dhirenmathur I'd like to contribute to this issue. Could you assigned this to me? Thanks!\n---\nGladly! Thank you and all the best!\n---\nHey @simin75simin what were your final findings?\n---\ncould not test comprehensively right now cause an issue in local repo reads: 'Repo' object has no method 'get_contents'\nit seems there are two packages used: gitPython (import git) and pyGithub (import github) and pyGithub has get_contents for production mode, which grabs the repo online. \ntrying to install production mode for now. @dhirenmathur\n---\n@simin75simin understood, we didn't face this bug when we were testing it that day correct? Did you try to test something different? Could you please provide steps to reproduce and open an issue for it? Thanks!\n---\nit seemed this bug is only present for anthropic. still trying to pin down how exactly it happened. maybe it's some network issue on my local PC that uses a proxy & WSL 2. but this does not look likely because i can use litellm & anthropic from python shell in the same terminal. maybe something else. \non my PC this error was triggered by going into the postgres docker container and added the preferred AI for the defaultuser to be 'anthropic' and followed readme. @dhirenmathur\n---\nIf you remove the preferred provider from db it works end to end like we tried previously?\n---\nyes, and if i change it to openai it also works, but if i change it to anthropic it gives UNEXPECTED_EOF_WHILE_READING and even though sometimes the call to the AI works Anthropic gives responses suggesting it cannot access context i.e. the repo. no problem with openai though.\n---\nAnd to confirm, you used the API to set the provider in the database? (To make sure that the format is correct in the database)\n---\nno but i can try\nalso if it's openai it works, like\n```sql\nUPDATE user_preferences\nSET preferences = '{\"llm_provider\": \"openai\"}'\nWHERE user_id = 'defaultuser';\n```\nbut if i change the word openai to anthropic it throws UNEXPECTED_EOF_WHILE_READING\n---\nso i tried using API to set provider in database but same error. i got a 200 from Anthropic but then started getting one UNEXPECTED_EOF_WHILE_READING. looking into this.\n---\nlooks like some format conversion mistake with Pydantic with PydanticOutputParser\n---\nhttps://github.com/potpie-ai/potpie/pull/230 @dhirenmathur\n---\nThis can be closed right? @dhirenmathur"
    },
    {
        "title": "docs: issues while following the getting started on a apple silion mac",
        "id": 2686596900,
        "state": "open",
        "first": "I followed the getting started guide for potpie development, I noticed that it does not successfully start running on my mac m2 pro. To start off I created a service account in a firebase account and installed it locally. A few packages weren't getting installed locally, got the following error when running `pip install -r requirements.txt`\r\n```\r\npip install -r requirements.txt                                                                       \u2500\u256f\r\nCollecting uvicorn (from -r requirements.txt (line 2))\r\n  Using cached uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\r\nRequirement already satisfied: sqlalchemy in /Users/vibhavbobade/miniconda3/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (2.0.36)\r\nRequirement already satisfied: alembic in /Users/vibhavbobade/miniconda3/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (1.14.0)\r\nCollecting gunicorn (from -r requirements.txt (line 5))\r\n  Using cached gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\r\n...\r\nERROR: Ignored the following versions that require a different python version: 0.0.1 Requires-Python <3.12,>=3.10; 0.0.10 Requires-Python <3.12,>=3.9; 0.0.10a0 Requires-Python <3.12,>=3.9; 0.0.11 Requires-Python <3.12,>=3.9; 0.0.12 Requires-Python <3.12,>=3.9; 0.0.13 Requires-Python <3.12,>=3.9; 0.0.14 Requires-Python <3.12,>=3.9; 0.0.15 Requires-Python <3.12,>=3.9; 0.0.16 Requires-Python <3.12,>=3.9; 0.0.17 Requires-Python <3.12,>=3.9; 0.0.18 Requires-Python <3.12,>=3.9; 0.0.19 Requires-Python <3.12,>=3.9; ...\r\nERROR: Could not find a version that satisfies the requirement blar-graph==1.0.11 (from versions: none)\r\nERROR: No matching distribution found for blar-graph==1.0.11\r\n```\r\nBased on the command above I understand that I have the wrong version of python installed which is right, I have \r\n```\r\npython --version                                                                                      \u2500\u256f\r\nPython 3.12.4\r\n```\r\na  < 3.12 version installed.\r\nThe docs is also missing dev dependency on albemic which is used for database migrations.\r\nMaybe, support for devcontainer could help here",
        "messages": "I followed the getting started guide for potpie development, I noticed that it does not successfully start running on my mac m2 pro. To start off I created a service account in a firebase account and installed it locally. A few packages weren't getting installed locally, got the following error when running `pip install -r requirements.txt`\r\n```\r\npip install -r requirements.txt                                                                       \u2500\u256f\r\nCollecting uvicorn (from -r requirements.txt (line 2))\r\n  Using cached uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\r\nRequirement already satisfied: sqlalchemy in /Users/vibhavbobade/miniconda3/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (2.0.36)\r\nRequirement already satisfied: alembic in /Users/vibhavbobade/miniconda3/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (1.14.0)\r\nCollecting gunicorn (from -r requirements.txt (line 5))\r\n  Using cached gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\r\n...\r\nERROR: Ignored the following versions that require a different python version: 0.0.1 Requires-Python <3.12,>=3.10; 0.0.10 Requires-Python <3.12,>=3.9; 0.0.10a0 Requires-Python <3.12,>=3.9; 0.0.11 Requires-Python <3.12,>=3.9; 0.0.12 Requires-Python <3.12,>=3.9; 0.0.13 Requires-Python <3.12,>=3.9; 0.0.14 Requires-Python <3.12,>=3.9; 0.0.15 Requires-Python <3.12,>=3.9; 0.0.16 Requires-Python <3.12,>=3.9; 0.0.17 Requires-Python <3.12,>=3.9; 0.0.18 Requires-Python <3.12,>=3.9; 0.0.19 Requires-Python <3.12,>=3.9; ...\r\nERROR: Could not find a version that satisfies the requirement blar-graph==1.0.11 (from versions: none)\r\nERROR: No matching distribution found for blar-graph==1.0.11\r\n```\r\nBased on the command above I understand that I have the wrong version of python installed which is right, I have \r\n```\r\npython --version                                                                                      \u2500\u256f\r\nPython 3.12.4\r\n```\r\na  < 3.12 version installed.\r\nThe docs is also missing dev dependency on albemic which is used for database migrations.\r\nMaybe, support for devcontainer could help here\n---\nThanks @waveywaves , will add this in the documentation"
    },
    {
        "title": "Centralised prompt management",
        "id": 2683451752,
        "state": "no reaction",
        "first": "# Centralize Prompt Management System\r\n## Problem\r\nPrompts are currently hardcoded across different files, making maintenance and model-specific optimizations difficult.\r\n## Proposed Solution\r\nCreate a dedicated prompt management system with:\r\n- Separate prompt files organized by provider/model\r\n- Dynamic loading based on provider/model combination\r\n- Fallback mechanism for unsupported combinations\r\n## Implementation Details\r\n1. Create new file(s) under `app/modules/intelligence/prompts`\r\n2. Implement loader function to:\r\n- Accept provider/model parameters\r\n- Attempt to load specific prompts\r\n- Fall back to default if not found\r\n## Acceptance Criteria\r\n- [ ] Structured prompt files by provider/model\r\n- [ ] Dynamic prompt loading system\r\n- [ ] Default fallback mechanism\r\n- [ ] Migration of existing hardcoded prompts",
        "messages": "# Centralize Prompt Management System\r\n## Problem\r\nPrompts are currently hardcoded across different files, making maintenance and model-specific optimizations difficult.\r\n## Proposed Solution\r\nCreate a dedicated prompt management system with:\r\n- Separate prompt files organized by provider/model\r\n- Dynamic loading based on provider/model combination\r\n- Fallback mechanism for unsupported combinations\r\n## Implementation Details\r\n1. Create new file(s) under `app/modules/intelligence/prompts`\r\n2. Implement loader function to:\r\n- Accept provider/model parameters\r\n- Attempt to load specific prompts\r\n- Fall back to default if not found\r\n## Acceptance Criteria\r\n- [ ] Structured prompt files by provider/model\r\n- [ ] Dynamic prompt loading system\r\n- [ ] Default fallback mechanism\r\n- [ ] Migration of existing hardcoded prompts"
    },
    {
        "title": "Add support for Ollama ",
        "id": 2683438871,
        "state": "open",
        "first": "**Overview**\r\nAdd support for Ollama to enable users to run open source models locally. \r\nThis feature is required for privacy focused users who do not want to share their code with LLM providers.\r\n**Requirements**\r\n* Integration with Ollama API using langchain\r\n* Support for multiple open source models available through Ollama\r\n* Seamless switching between cloud and local models using the providers API \r\n**Technical Details**\r\n* Implement Ollama API client\r\n* Add configuration options for Ollama endpoint and model selection\r\n* Ensure compatibility with existing application interfaces\r\n**Success Criteria**\r\n* Users can run local models through Ollama\r\n* Successful Knowledge graph creation and agent execution.",
        "messages": "**Overview**\r\nAdd support for Ollama to enable users to run open source models locally. \r\nThis feature is required for privacy focused users who do not want to share their code with LLM providers.\r\n**Requirements**\r\n* Integration with Ollama API using langchain\r\n* Support for multiple open source models available through Ollama\r\n* Seamless switching between cloud and local models using the providers API \r\n**Technical Details**\r\n* Implement Ollama API client\r\n* Add configuration options for Ollama endpoint and model selection\r\n* Ensure compatibility with existing application interfaces\r\n**Success Criteria**\r\n* Users can run local models through Ollama\r\n* Successful Knowledge graph creation and agent execution.\n---\n@dhirenmathur I would like to work on this, can you assign it to me.\n---\n@waveywaves are you working on this or can I assign it to someone else?\n---\n@dhirenmathur hey Dhiren! continuing work on this... shall post an update through the next day"
    },
    {
        "title": "Generate Unit Tests for github_service.py",
        "id": 2645726402,
        "state": "open",
        "first": "**Description:**\r\nWe need to create unit tests for the `github_service.py` file located in the `app/modules/github/` directory. The goal is to ensure that all functions are thoroughly tested for expected behavior, edge cases, and error handling.\r\n**Functions to Test:**\r\n1. **get_github_repo_details**: Test the retrieval of GitHub repository details, including handling of invalid repository names and API errors.\r\n2. **get_file_content**: Validate file content retrieval, including:\r\n   - Successful access to private and public repositories.\r\n   - Handling of directory paths instead of file paths.\r\n   - Correct line selection based on `start_line` and `end_line`.\r\n3. **get_repos_for_user**: Validate the retrieval of repositories for a user, including error handling for missing users and tokens.\r\n4. **get_combined_user_repos**: Test the combination of user repositories and project repositories, ensuring no duplicates.\r\n5. **get_branch_list**: Validate branch retrieval, including error handling for non-existent repositories.\r\n6. **get_public_github_instance**: Ensure that a public GitHub instance is returned correctly.\r\n7. **get_repo**: Test the retrieval of a repository, including handling of both private and public access failures.\r\n8. **get_project_structure_async**: Validate the fetching of project structure, including caching behavior.\r\n**Testing Framework:**\r\n- Use `pytest` for writing the unit tests.\r\n- Consider using `pytest-mock` or `unittest.mock` to mock external dependencies like GitHub API calls and database interactions.\r\n**Acceptance Criteria:**\r\n- All functions have corresponding unit tests.\r\n- Tests cover both happy paths and edge cases.\r\n- Code coverage should be at least 80%.\r\n**Additional Notes:**\r\n- Please ensure that the tests are organized and follow best practices for readability and maintainability.",
        "messages": "**Description:**\r\nWe need to create unit tests for the `github_service.py` file located in the `app/modules/github/` directory. The goal is to ensure that all functions are thoroughly tested for expected behavior, edge cases, and error handling.\r\n**Functions to Test:**\r\n1. **get_github_repo_details**: Test the retrieval of GitHub repository details, including handling of invalid repository names and API errors.\r\n2. **get_file_content**: Validate file content retrieval, including:\r\n   - Successful access to private and public repositories.\r\n   - Handling of directory paths instead of file paths.\r\n   - Correct line selection based on `start_line` and `end_line`.\r\n3. **get_repos_for_user**: Validate the retrieval of repositories for a user, including error handling for missing users and tokens.\r\n4. **get_combined_user_repos**: Test the combination of user repositories and project repositories, ensuring no duplicates.\r\n5. **get_branch_list**: Validate branch retrieval, including error handling for non-existent repositories.\r\n6. **get_public_github_instance**: Ensure that a public GitHub instance is returned correctly.\r\n7. **get_repo**: Test the retrieval of a repository, including handling of both private and public access failures.\r\n8. **get_project_structure_async**: Validate the fetching of project structure, including caching behavior.\r\n**Testing Framework:**\r\n- Use `pytest` for writing the unit tests.\r\n- Consider using `pytest-mock` or `unittest.mock` to mock external dependencies like GitHub API calls and database interactions.\r\n**Acceptance Criteria:**\r\n- All functions have corresponding unit tests.\r\n- Tests cover both happy paths and edge cases.\r\n- Code coverage should be at least 80%.\r\n**Additional Notes:**\r\n- Please ensure that the tests are organized and follow best practices for readability and maintainability.\n---\n@dhirenmathur I'd like to take up this issue. The tests should go into which folder?\n---\n@Anu-Ra-g that's great, you should create a new folder in the root directory of the project called `tests`\n---\nI'm using this for setting up the `tests/module/github/test_github_service.py` package, instead of using `__init__.py`\r\n```\r\nsys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../../../')))\r\nfrom app.modules.github.github_service import GithubService\r\n```\r\nWill it be okay?\n---\n@Anu-Ra-g I would recommend to stick to creating the init file, this approach could end up being difficult to maintain and run tests from other directories\n---\n@Anu-Ra-g let us know if you need any help\n---\n@Anu-Ra-g are you still working on this?\n---\nYes, I'm still working on this but I got a little busy. I will make the PR as soon as possible.\n---\nGo ahead\n---\n@dhirenmathur I'd like to solve this one as well if that is okay.\n---\n@simin75simin let's do the issues one at a time so that others have a chance as well, there's already an open PR for this one too :)\n---\n> [@simin75simin](https://github.com/simin75simin) let's do the issues one at a time so that others have a chance as well, there's already an open PR for this one too :)\nsorry just looking for things to contribute and this one seemed dormant\n---\nYou are right that this is dormant @simin75simin, if we can validate that no work is needed in the other issue, you can pick this up! Thank you!\n---\nCould I try working on this?"
    },
    {
        "title": "Implement Comprehensive Development Mode ",
        "id": 2645696128,
        "state": "closed",
        "first": "## Overview\r\nThe `isDevelopmentMode` flag is designed to disable third-party services (Firebase, GitHub, Portkey, AgentOps) to enable local development with minimal setup. Several components need to be modified to properly handle this development mode.\r\n## Current Issue\r\n- High time to get started with contribution\r\n## Required Changes\r\n### 1. Main Application (`main.py`)\r\n- [ ] Add validation to ensure `isDevelopmentMode` is only enabled when `ENV='development'`\r\n- [ ] Implement error handling for mismatched configurations\r\n- [ ] Add logging for development mode status on startup\r\n### 2. Authentication Service (`auth_service.py`)\r\n- [ ] Prevent Firebase initialization in development mode\r\n- [ ] Implement mock authentication that returns:\r\n  ```python\r\n  {\"user_id\": os.getenv(\"defaultUsername\")}\r\n  ```\r\n- [ ] Add clear logging when using mock authentication\r\n### 3. Provider Service (`provider_service.py`)\r\n- [ ] Modify ChatOpenAI initialization to bypass Portkey in development mode\r\n- [ ] Modify ChatAnthropic initialization to bypass Portkey in development mode\r\n- [ ] Add configuration validation for both providers\r\n- [ ] Implement logging for provider initialization status\r\n### 4. GitHub Service (`github_service.py`)\r\n- [ ] Prevent GitHub client initialization in development mode\r\n- [ ] Implement local repository operations:\r\n  - [ ] Directory scanning\r\n  - [ ] Local git operations for metadata\r\n  - [ ] File reading capabilities\r\n- [ ] Modify get_code functions to read from neo4j node 'text' key for local repos\r\n- [ ] Add validation for required local repo structure\r\n### 5. Secret Manager\r\n- [ ] Prevent secret manager initialization in development mode\r\n- [ ] Implement local alternative for secrets (env variables)\r\n- [ ] Add validation for required development environment variables\r\n## Documentation Updates Needed\r\nUpdate teh Getting Started file with - \r\n- [ ] Development mode setup instructions\r\n- [ ] Local repository requirements\r\n- [ ] Environment variable documentation\r\n- [ ] Troubleshooting guide\r\n## Acceptance Criteria\r\n1. Application starts successfully in development mode with single start.sh file\r\n2. No third-party service initialization occurs in development mode\r\n3. All core functionality works with local alternatives\r\n4. Clear error messages for misconfiguration\r\n5. Comprehensive logging of development mode status",
        "messages": "## Overview\r\nThe `isDevelopmentMode` flag is designed to disable third-party services (Firebase, GitHub, Portkey, AgentOps) to enable local development with minimal setup. Several components need to be modified to properly handle this development mode.\r\n## Current Issue\r\n- High time to get started with contribution\r\n## Required Changes\r\n### 1. Main Application (`main.py`)\r\n- [ ] Add validation to ensure `isDevelopmentMode` is only enabled when `ENV='development'`\r\n- [ ] Implement error handling for mismatched configurations\r\n- [ ] Add logging for development mode status on startup\r\n### 2. Authentication Service (`auth_service.py`)\r\n- [ ] Prevent Firebase initialization in development mode\r\n- [ ] Implement mock authentication that returns:\r\n  ```python\r\n  {\"user_id\": os.getenv(\"defaultUsername\")}\r\n  ```\r\n- [ ] Add clear logging when using mock authentication\r\n### 3. Provider Service (`provider_service.py`)\r\n- [ ] Modify ChatOpenAI initialization to bypass Portkey in development mode\r\n- [ ] Modify ChatAnthropic initialization to bypass Portkey in development mode\r\n- [ ] Add configuration validation for both providers\r\n- [ ] Implement logging for provider initialization status\r\n### 4. GitHub Service (`github_service.py`)\r\n- [ ] Prevent GitHub client initialization in development mode\r\n- [ ] Implement local repository operations:\r\n  - [ ] Directory scanning\r\n  - [ ] Local git operations for metadata\r\n  - [ ] File reading capabilities\r\n- [ ] Modify get_code functions to read from neo4j node 'text' key for local repos\r\n- [ ] Add validation for required local repo structure\r\n### 5. Secret Manager\r\n- [ ] Prevent secret manager initialization in development mode\r\n- [ ] Implement local alternative for secrets (env variables)\r\n- [ ] Add validation for required development environment variables\r\n## Documentation Updates Needed\r\nUpdate teh Getting Started file with - \r\n- [ ] Development mode setup instructions\r\n- [ ] Local repository requirements\r\n- [ ] Environment variable documentation\r\n- [ ] Troubleshooting guide\r\n## Acceptance Criteria\r\n1. Application starts successfully in development mode with single start.sh file\r\n2. No third-party service initialization occurs in development mode\r\n3. All core functionality works with local alternatives\r\n4. Clear error messages for misconfiguration\r\n5. Comprehensive logging of development mode status\n---\nFor the provider is it possible for the user to use a locally hosted model such as something fro huggingface ?\nFor the GitHub service which focuses on GitHub, it should be possible for users to use their own git server like gittea.\n---\n@waveywaves \r\n>For the provider is it possible for the user to use a locally hosted model such as something fro huggingface ?\r\nWe do have support for other local as well as open source models planned as a separate feature. \r\n>For the GitHub service which focuses on GitHub, it should be possible for users to use their own git server like gittea.\r\nFor Github the future integrations will be more along the lines of bitbucket etc which are more widely used \r\nDo you want to work on this issue?\n---\n@dhirenmathur yep can you assign me to this issue ?\n---\nLet me know if you need any help @waveywaves\n---\n@waveywaves were you able to get started?\n---\nHey @dhirenmathur getting started on it today and plan on working through it tomorrow, I'll update this issue with a draft PR soon\n---\nhi @waveywaves I am going to pick up the accommodation for tools / code fetching services for supporting local repos , removing their tight coupling with GitHub as part of another internal improvement. \r\nyou can continue with rest of the implementation.\n---\n@vineetshar sounds good to me\n---\nfirst PR for this issue \r\nhttps://github.com/potpie-ai/potpie/pull/192\n---\n@dhirenmathur we can mark 1,2,3 over here as done. Shall open a PR for 5 soon.\n---\n@waveywaves   1,2,3,4,5 all are done now.\n---\n@vineetshar that's awesome ! ~Do we still need comprehensive documentation on this ? If so I can contribute to it.~\r\njust saw https://github.com/potpie-ai/potpie/pull/195 PR, looking forward to testing it out locally"
    },
    {
        "title": "\"LLM Provider NOT provided\" Error for Non-OpenAI Models in Litellm",
        "id": 2631253372,
        "state": "closed",
        "first": "Description: CrewAI uses the Litellm library to route LLM requests to the appropriate model. Currently, Litellm throws an error, \"LLM Provider NOT provided\", whenever a request is made for a non-OpenAI model, preventing proper routing to other providers.\r\nExpected Behavior: Litellm should handle non-OpenAI models without throwing an error, allowing CrewAI to route requests to the correct LLM as specified.\r\nSteps to Reproduce:\r\n* Configure CrewAI to use a non-OpenAI LLM provider through Litellm using the following API: \r\n```\r\ncurl -X POST \"http://localhost:8001/api/v1/set-global-ai-provider/\" \\\r\n-H \"Authorization: Bearer <API_TOKEN>\" \\\r\n-H \"Content-Type: application/json\" \\\r\n-d '{\r\n  \"provider\": \"anthropic\"\r\n}'\r\n```\r\n* Set the anthropic API key \"ANTHROPIC_API_KEY\" in your .env \r\n* Create a conversation: \r\n```\r\ncurl -X 'POST' \\\r\n  'http://localhost:8001/api/v1/conversations/' \\\r\n  -H 'accept: application/json' \\\r\n  -H 'Content-Type: application/json' \\\r\n  -d '{\r\n  \"user_id\": \"your_user_id\",\r\n  \"title\": \"Conversation Title\",\r\n  \"status\": \"active\",\r\n  \"project_ids\": [\r\n    \"project_id\"\r\n  ],\r\n  \"agent_ids\": [\r\n    \"codebase_qna_agent\"\r\n  ]\r\n}'\r\n```\r\n* Send message: \r\n```\r\ncurl -X 'POST' \\\r\n  'http://localhost:8001/api/v1/conversations/1234/message/' \\\r\n  -H 'accept: application/json' \\\r\n  -H 'Content-Type: application/json' \\\r\n  -d '{\r\n  \"content\": \"Your message content here\",\r\n  \"node_ids\": [\r\n    {\r\n      \"node_id\": \"node_identifier\",\r\n      \"name\": \"node_name\"\r\n    }\r\n  ]\r\n}'\r\n```",
        "messages": "Description: CrewAI uses the Litellm library to route LLM requests to the appropriate model. Currently, Litellm throws an error, \"LLM Provider NOT provided\", whenever a request is made for a non-OpenAI model, preventing proper routing to other providers.\r\nExpected Behavior: Litellm should handle non-OpenAI models without throwing an error, allowing CrewAI to route requests to the correct LLM as specified.\r\nSteps to Reproduce:\r\n* Configure CrewAI to use a non-OpenAI LLM provider through Litellm using the following API: \r\n```\r\ncurl -X POST \"http://localhost:8001/api/v1/set-global-ai-provider/\" \\\r\n-H \"Authorization: Bearer <API_TOKEN>\" \\\r\n-H \"Content-Type: application/json\" \\\r\n-d '{\r\n  \"provider\": \"anthropic\"\r\n}'\r\n```\r\n* Set the anthropic API key \"ANTHROPIC_API_KEY\" in your .env \r\n* Create a conversation: \r\n```\r\ncurl -X 'POST' \\\r\n  'http://localhost:8001/api/v1/conversations/' \\\r\n  -H 'accept: application/json' \\\r\n  -H 'Content-Type: application/json' \\\r\n  -d '{\r\n  \"user_id\": \"your_user_id\",\r\n  \"title\": \"Conversation Title\",\r\n  \"status\": \"active\",\r\n  \"project_ids\": [\r\n    \"project_id\"\r\n  ],\r\n  \"agent_ids\": [\r\n    \"codebase_qna_agent\"\r\n  ]\r\n}'\r\n```\r\n* Send message: \r\n```\r\ncurl -X 'POST' \\\r\n  'http://localhost:8001/api/v1/conversations/1234/message/' \\\r\n  -H 'accept: application/json' \\\r\n  -H 'Content-Type: application/json' \\\r\n  -d '{\r\n  \"content\": \"Your message content here\",\r\n  \"node_ids\": [\r\n    {\r\n      \"node_id\": \"node_identifier\",\r\n      \"name\": \"node_name\"\r\n    }\r\n  ]\r\n}'\r\n```\n---\nI will try to reproduce this issue, currently facing some issues regarding running code on wsl.\n---\n![image](https://github.com/user-attachments/assets/83fe4a3d-38dc-413b-bdec-dd061e39478c)\r\nI'm encountering a connection error after running ```./start.sh.``` It seems that:\r\n``` POSTGRES_SERVER=postgresql://postgres:mysecretpassword@host.docker.internal:5432/momentum ```\r\nis not resolving to the proper IP in WSL. I'm using the non-WSL version of that variable, which resolves the issue, but now I'm getting an incorrect password error.\r\nalthough when I connect to psql via shell and force it to ask for password even if I type random password, it connects \r\nis this a known issue @dhirenmathur?\n---\nNot a known issue @palash018 , is this a blocker or were you able to proceed with the task?\n---\n@dhirenmathur it is actually a blocker since I cannot even run the code itself due to this issue. issue presents itself in ```./start.sh``` itself\n---\nGot it, I'll try to reproduce and get back to you\n---\nFixed today, can be closed @dhirenmathur\n---\nYes, let's close it"
    },
    {
        "title": "Stuck after logging in via Github - the Getting Started page from the website doesn't redirect to New Chat after authentication.",
        "id": 2630303040,
        "state": "open",
        "first": "Description\r\nThe Getting Started flow from the website doesn't redirect to the new chat/actionable page for potpie. I've already installed potpie on 2 repositories. When I was actually a new user, this worked. So it's only for returning users. \r\nIdeally, as a user I should have clicked the Sign In button, but Getting Started was more intuitive since I hadn't actually 'used' Potpie after installing it. \r\nSteps to Reproduce\r\n1. Install potpie on Github/add repository\r\n2. Click Getting Started on the website. \r\n3. Login with the same Github account\r\n4. Takes you to Integrations tab with Potpie open/installed.\r\n5. Does not redirect to New Chat/actionable flow for user.\r\nLet me know if you'd like any additional details added!\r\n<img width=\"1101\" alt=\"image\" src=\"https://github.com/user-attachments/assets/e4967b2b-8aac-4091-b045-8ba0e1ff8262\">",
        "messages": "Description\r\nThe Getting Started flow from the website doesn't redirect to the new chat/actionable page for potpie. I've already installed potpie on 2 repositories. When I was actually a new user, this worked. So it's only for returning users. \r\nIdeally, as a user I should have clicked the Sign In button, but Getting Started was more intuitive since I hadn't actually 'used' Potpie after installing it. \r\nSteps to Reproduce\r\n1. Install potpie on Github/add repository\r\n2. Click Getting Started on the website. \r\n3. Login with the same Github account\r\n4. Takes you to Integrations tab with Potpie open/installed.\r\n5. Does not redirect to New Chat/actionable flow for user.\r\nLet me know if you'd like any additional details added!\r\n<img width=\"1101\" alt=\"image\" src=\"https://github.com/user-attachments/assets/e4967b2b-8aac-4091-b045-8ba0e1ff8262\">\n---\n@srishti-56 Thanks for reporting this! \r\n@vineetshar can you take a look at the Github app settings please.\n---\nHey @srishti-56 this was an issue on the UI, we fixed this a couple days back, can you try again? Thanks!\n---\nHmm, just checked, it still doesn't redirect to the chat page\n---\n@srishti-56 please try changing the repository selection and try again\n---\n@srishti-56 can you confirm whether it worked so that I can close the issue?\n---\ni changed the selected repository (deleted one of them) it redirected back to the 'Continue with Github' page..to clarify, this page doesn't appear -\r\n<img width=\"1117\" alt=\"image\" src=\"https://github.com/user-attachments/assets/b692687b-e2e7-4968-a091-dea79b221f73\">"
    },
    {
        "title": "Search Indexes are not being copied for pre-parsed repos",
        "id": 2624161820,
        "state": "open",
        "first": "When someone tries to parse a pre-processed repos, search indexes are not being copied.",
        "messages": "When someone tries to parse a pre-processed repos, search indexes are not being copied.\n---\nHey @vineetshar , I'd love to work on this issue.\n---\nSure you can pick this up"
    },
    {
        "title": "Update Task Status to \"Errored\" on Celery Timeout Exceedance",
        "id": 2624146648,
        "state": "open",
        "first": "**Description:**\r\nCurrently, when a parsing task exceeds the approved time limit, Celery terminates the task but does not update its status to \"Errored.\" This leads to tasks appearing incomplete or stuck without indicating the timeout failure, which can hinder error tracking and debugging.\r\n**Proposed Solution:**\r\n- Implement logic to detect when a task is killed due to exceeding the time limit and update its status to \"Errored.\"\r\n- Ensure that all tasks handle timeouts gracefully, providing clear feedback on task status for easier monitoring and troubleshooting.\r\n**Tasks:**\r\n- [ ] Add error handling in the task code to catch Celery timeouts and update the task status to \"Errored.\"\r\n- [ ] Implement logging for timeout events to aid in debugging and tracking task failures.\r\n- [ ] Test to verify that tasks exceeding the time limit are properly marked as \"Errored\" in the system.\r\n**Acceptance Criteria:**\r\n- Tasks that exceed the Celery time limit are automatically marked as \"Errored.\"\r\n- Logging is in place to capture details of timeout occurrences.",
        "messages": "**Description:**\r\nCurrently, when a parsing task exceeds the approved time limit, Celery terminates the task but does not update its status to \"Errored.\" This leads to tasks appearing incomplete or stuck without indicating the timeout failure, which can hinder error tracking and debugging.\r\n**Proposed Solution:**\r\n- Implement logic to detect when a task is killed due to exceeding the time limit and update its status to \"Errored.\"\r\n- Ensure that all tasks handle timeouts gracefully, providing clear feedback on task status for easier monitoring and troubleshooting.\r\n**Tasks:**\r\n- [ ] Add error handling in the task code to catch Celery timeouts and update the task status to \"Errored.\"\r\n- [ ] Implement logging for timeout events to aid in debugging and tracking task failures.\r\n- [ ] Test to verify that tasks exceeding the time limit are properly marked as \"Errored\" in the system.\r\n**Acceptance Criteria:**\r\n- Tasks that exceed the Celery time limit are automatically marked as \"Errored.\"\r\n- Logging is in place to capture details of timeout occurrences.\n---\nCan i work on this?\n---\n@Pratik-Sharma-Dev sure, have you gone through the codebase? what's your plan of action?\n---\n@vineetshar @dhirenmathur  , I would like to ask if @Pratik-Sharma-Dev or anyone is working on this or not, if not then I would like to work on this.\r\nAs, I have gone through the codebase (partials) and proposed solution, here is the key point upon which we have to work:\r\n1. Review the task timeout configuration (`time_limit` and `soft_time_limit`, i.e. mechanism to handle task execution time limits in a controlled way. It allow tasks to gracefully terminate when they exceed their allotted time without abruptly killing the process. ) for `parsing_task.py` and identify where timeout events can be intercepted.\r\n2. Modify `parsing_task.py` to catch the `SoftTimeLimitExceeded` exception and ensure the task status is updated to \"Errored\" in the database.\r\n3. Add logging for timeout events to capture details like task ID, task name, and failure time for easier debugging."
    },
    {
        "title": "Restrict Further Sharing of Shared Chats in Chat API",
        "id": 2624130319,
        "state": "open",
        "first": "**Description:**\r\nCurrently, the chat-sharing feature permits secondary sharing, where users with whom a chat is shared (e.g., User B) can share it further with others (e.g., User C). This creates potential privacy and control concerns, as the original chat creator may not intend for additional sharing.\r\n**Proposed Solution:**\r\n- Implement restrictions within the Chat API that prevent secondary users from sharing the chat further.\r\n- Only the original creator (User A) should retain the permission to share access.\r\n**Tasks:**\r\n- [ ] Update the chat-sharing logic to restrict further sharing permissions to only the chat creator.\r\n- [ ] Add checks within the API to verify user permissions before allowing share actions.\r\n- [ ] Test the sharing restrictions to confirm expected behaviour.\r\n**Acceptance Criteria:**\r\n- Only the original creator can share a chat.\r\n- Secondary users (those with whom a chat is shared) are restricted from sharing the chat further.",
        "messages": "**Description:**\r\nCurrently, the chat-sharing feature permits secondary sharing, where users with whom a chat is shared (e.g., User B) can share it further with others (e.g., User C). This creates potential privacy and control concerns, as the original chat creator may not intend for additional sharing.\r\n**Proposed Solution:**\r\n- Implement restrictions within the Chat API that prevent secondary users from sharing the chat further.\r\n- Only the original creator (User A) should retain the permission to share access.\r\n**Tasks:**\r\n- [ ] Update the chat-sharing logic to restrict further sharing permissions to only the chat creator.\r\n- [ ] Add checks within the API to verify user permissions before allowing share actions.\r\n- [ ] Test the sharing restrictions to confirm expected behaviour.\r\n**Acceptance Criteria:**\r\n- Only the original creator can share a chat.\r\n- Secondary users (those with whom a chat is shared) are restricted from sharing the chat further.\n---\ncould you assign this to me?\n---\nHey sure @malikrohail feel free to pick this up.\n---\non it, could you pls share repo guidelines for the pull request?\n---\n@malikrohail  I dont think we are enforcing a lot yet. Just ensure you follow semantic titles and add comments in code & description in pull request with curl screenshots / api call screenshots as proof of functionality.\n---\nHi @malikrohail let us know if you need any help\n---\n@dhirenmathur should this not be closed too?"
    },
    {
        "title": "Migrate Database Interactions to Async Using `asyncpg`",
        "id": 2624114506,
        "state": "open",
        "first": "**Description:**\r\nTo improve the performance and responsiveness of our APIs and services, we should transition from synchronous database interactions to asynchronous ones. By adopting `asyncpg` as our database interface, we align with the goal of providing truly asynchronous interfaces and runtime for all APIs and services.\r\n**Proposed Solution:**\r\n- Replace current synchronous database connections and queries with asynchronous implementations using `asyncpg`.\r\n- Ensure all relevant service calls are updated to handle async database operations properly.\r\n**Tasks:**\r\n- [ ] Research `asyncpg` capabilities and compatibility with our existing database structure.\r\n- [ ] Refactor database connection initialization to use `asyncpg`.\r\n- [ ] Update all current synchronous queries to asynchronous with `asyncpg`.\r\n- [ ] Test async implementations to verify expected performance improvements.\r\n- [ ] Update documentation to reflect the new async architecture.\r\n**Acceptance Criteria:**\r\n- All database interactions are asynchronous, providing a non-blocking runtime.\r\n- All API endpoints and services leverage async for better concurrency and performance.",
        "messages": "**Description:**\r\nTo improve the performance and responsiveness of our APIs and services, we should transition from synchronous database interactions to asynchronous ones. By adopting `asyncpg` as our database interface, we align with the goal of providing truly asynchronous interfaces and runtime for all APIs and services.\r\n**Proposed Solution:**\r\n- Replace current synchronous database connections and queries with asynchronous implementations using `asyncpg`.\r\n- Ensure all relevant service calls are updated to handle async database operations properly.\r\n**Tasks:**\r\n- [ ] Research `asyncpg` capabilities and compatibility with our existing database structure.\r\n- [ ] Refactor database connection initialization to use `asyncpg`.\r\n- [ ] Update all current synchronous queries to asynchronous with `asyncpg`.\r\n- [ ] Test async implementations to verify expected performance improvements.\r\n- [ ] Update documentation to reflect the new async architecture.\r\n**Acceptance Criteria:**\r\n- All database interactions are asynchronous, providing a non-blocking runtime.\r\n- All API endpoints and services leverage async for better concurrency and performance.\n---\nHi @vineetshar, can i work on this issue? can you please assign me?\n---\nYes @sarfarazsiddiquii this still needs to be done, sure you can pick it up. Let us know the plan of action here before you start implementing.\n---\nHey @vineetshar \r\nsure! I'll replace the current synchronous `SQLAlchemy` queries with asynchronous queries using `asyncpg` in `database.py`. Then, I will update all the database interactions (mainly in the `modules` directory) to use this new async approach.\n---\nHi @vineetshar is everything alright in the method I mentioned?\r\nShould I start with the issue?\n---\nHey @sarfarazsiddiquii yes you can proceed\n---\nHey @sarfarazsiddiquii let us know if you need any help\n---\nHey @dhirenmathur, I am a bit confused about the approach. I\u2019ve updated [database.py to use async operations](https://github.com/sarfarazsiddiquii/potpie/commit/9e2333f2efb37acab250e85a96a20c1bec5c213a). \r\nHowever, many files use synchronous database operations. Do we need to manually update all of these to async, or is there a way to streamline the process?"
    },
    {
        "title": "Fix Errors Raised by Pre-Commit Hook in GitHub Action",
        "id": 2623930204,
        "state": "open",
        "first": "#### Description\r\nThe pre-commit hook is currently failing during the GitHub Action workflow. This issue outlines the necessary steps to identify and fix these errors to ensure a smooth development & CI/CD process.\r\n#### Steps to Reproduce\r\n1. Trigger the GitHub Action workflow with the current setup via raising a PR.\r\n2. Observe the errors raised by the pre-commit hook during the workflow run.\r\n#### Expected Outcome\r\nThe pre-commit hook should pass without any errors during the GitHub Action workflow.\r\n#### Tasks\r\n- [ ] Identify the specific errors raised by the pre-commit hook in the GitHub Action logs.\r\n- [ ] Adjust the code or pre-commit configuration as needed to address these errors.\r\n- [ ] Test the pre-commit hook locally to ensure no errors before committing.\r\n- [ ] Rerun the GitHub Action workflow to verify that the pre-commit hook passes successfully.\r\n#### Additional Information\r\nInclude logs, screenshots, or details about the errors raised by the pre-commit hook, if available. \r\nLet me know if you'd like any additional details added!",
        "messages": "#### Description\r\nThe pre-commit hook is currently failing during the GitHub Action workflow. This issue outlines the necessary steps to identify and fix these errors to ensure a smooth development & CI/CD process.\r\n#### Steps to Reproduce\r\n1. Trigger the GitHub Action workflow with the current setup via raising a PR.\r\n2. Observe the errors raised by the pre-commit hook during the workflow run.\r\n#### Expected Outcome\r\nThe pre-commit hook should pass without any errors during the GitHub Action workflow.\r\n#### Tasks\r\n- [ ] Identify the specific errors raised by the pre-commit hook in the GitHub Action logs.\r\n- [ ] Adjust the code or pre-commit configuration as needed to address these errors.\r\n- [ ] Test the pre-commit hook locally to ensure no errors before committing.\r\n- [ ] Rerun the GitHub Action workflow to verify that the pre-commit hook passes successfully.\r\n#### Additional Information\r\nInclude logs, screenshots, or details about the errors raised by the pre-commit hook, if available. \r\nLet me know if you'd like any additional details added!\n---\nHi @vineetshar, can you please confirm if this is still an issue? if it is can you assign it to me?\n---\nSure, but do you wanna finish up the other one first?"
    }
]